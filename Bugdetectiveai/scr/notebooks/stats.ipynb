{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "db83bc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join('..')))\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import hashlib\n",
    "\n",
    "from data_loader.loader import load_buggy_dataset, load_data, save_data\n",
    "from bug_detective.detective import process_prompt_dataset\n",
    "from utils.visualization import compare_groundtruth_vs_corrected_histograms, compare_metrics_versus_bug_histograms, plot_column_distribution, plot_metrics_boxplots\n",
    "from utils.simple_metrics import compute_and_store_metrics\n",
    "from typing import Dict,List\n",
    "\n",
    "\n",
    "data_path = '/Users/zanchitta/Developer/BugDetectiveAI/Bugdetectiveai/data/checkpoints/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b841d5",
   "metadata": {},
   "source": [
    "### Load all Experiments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cce6b385",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_identifier(df: pd.DataFrame, prompt: str) -> pd.DataFrame:\n",
    "    df['sample_uuid'] = df.apply(\n",
    "        lambda row: hashlib.md5(\n",
    "            (row['before_merge_without_docstrings'] + row['after_merge_without_docstrings']).encode('utf-8')\n",
    "        ).hexdigest(),\n",
    "        axis=1\n",
    "    )\n",
    "    df['prompt'] = prompt\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "db5df028",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = load_data(data_path + \"300_metrics_prompt_baseline_system_none.pkl\")\n",
    "system_apr = load_data(data_path + \"300_metrics_prompt_baseline_system_apr.pkl\")\n",
    "prompt_style = load_data(data_path + \"300_metrics_prompt_style_based.pkl\")\n",
    "\n",
    "baseline = create_identifier(baseline,\"baseline\")\n",
    "system_apr = create_identifier(system_apr,\"system_apr\")\n",
    "prompt_style = create_identifier(prompt_style,\"prompt_style\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "230b2e0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>before_merge_without_docstrings</th>\n",
       "      <th>after_merge_without_docstrings</th>\n",
       "      <th>traceback_type</th>\n",
       "      <th>full_traceback</th>\n",
       "      <th>response_qwen-2.5-coder-32b-instruct</th>\n",
       "      <th>response_codestral-2501</th>\n",
       "      <th>response_gpt-4o</th>\n",
       "      <th>response_claude-3.5-sonnet</th>\n",
       "      <th>metric_qwen-2.5-coder-32b-instruct_ast_score</th>\n",
       "      <th>metric_qwen-2.5-coder-32b-instruct_text_score</th>\n",
       "      <th>metric_qwen-2.5-coder-32b-instruct_ast_score_normalized</th>\n",
       "      <th>metric_qwen-2.5-coder-32b-instruct_codebleu</th>\n",
       "      <th>metric_qwen-2.5-coder-32b-instruct_ngram_match_score</th>\n",
       "      <th>metric_qwen-2.5-coder-32b-instruct_weighted_ngram_match_score</th>\n",
       "      <th>metric_qwen-2.5-coder-32b-instruct_syntax_match_score</th>\n",
       "      <th>metric_qwen-2.5-coder-32b-instruct_dataflow_match_score</th>\n",
       "      <th>metric_codestral-2501_ast_score</th>\n",
       "      <th>metric_codestral-2501_text_score</th>\n",
       "      <th>metric_codestral-2501_ast_score_normalized</th>\n",
       "      <th>metric_codestral-2501_codebleu</th>\n",
       "      <th>metric_codestral-2501_ngram_match_score</th>\n",
       "      <th>metric_codestral-2501_weighted_ngram_match_score</th>\n",
       "      <th>metric_codestral-2501_syntax_match_score</th>\n",
       "      <th>metric_codestral-2501_dataflow_match_score</th>\n",
       "      <th>metric_gpt-4o_ast_score</th>\n",
       "      <th>metric_gpt-4o_text_score</th>\n",
       "      <th>metric_gpt-4o_ast_score_normalized</th>\n",
       "      <th>metric_gpt-4o_codebleu</th>\n",
       "      <th>metric_gpt-4o_ngram_match_score</th>\n",
       "      <th>metric_gpt-4o_weighted_ngram_match_score</th>\n",
       "      <th>metric_gpt-4o_syntax_match_score</th>\n",
       "      <th>metric_gpt-4o_dataflow_match_score</th>\n",
       "      <th>metric_claude-3.5-sonnet_ast_score</th>\n",
       "      <th>metric_claude-3.5-sonnet_text_score</th>\n",
       "      <th>metric_claude-3.5-sonnet_ast_score_normalized</th>\n",
       "      <th>metric_claude-3.5-sonnet_codebleu</th>\n",
       "      <th>metric_claude-3.5-sonnet_ngram_match_score</th>\n",
       "      <th>metric_claude-3.5-sonnet_weighted_ngram_match_score</th>\n",
       "      <th>metric_claude-3.5-sonnet_syntax_match_score</th>\n",
       "      <th>metric_claude-3.5-sonnet_dataflow_match_score</th>\n",
       "      <th>sample_uuid</th>\n",
       "      <th>prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>75748</th>\n",
       "      <td>def run(self, cmd, **kwargs):\\n        sel...</td>\n",
       "      <td>def run(self, cmd, **kwargs):\\n        sel...</td>\n",
       "      <td>IndexError</td>\n",
       "      <td>An unexpected error has occurred: IndexError: ...</td>\n",
       "      <td>def run(self, cmd, **kwargs):\\n    self._creat...</td>\n",
       "      <td>def run(self, cmd, **kwargs):\\n    self._creat...</td>\n",
       "      <td>def run(self, cmd, **kwargs):\\n    self._creat...</td>\n",
       "      <td>def run(self, cmd, **kwargs):\\n    self._creat...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.688742</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.533997</td>\n",
       "      <td>0.422525</td>\n",
       "      <td>0.432303</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.826667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.533997</td>\n",
       "      <td>0.422525</td>\n",
       "      <td>0.432303</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.456522</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.534863</td>\n",
       "      <td>4.311807e-01</td>\n",
       "      <td>0.432303</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.498246</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.484122</td>\n",
       "      <td>0.294467</td>\n",
       "      <td>0.339630</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>8caf7a732dd1acbd2731a012a8bd45fe</td>\n",
       "      <td>baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583899</th>\n",
       "      <td>def process(self, argv=None, executable=No...</td>\n",
       "      <td>def process(self, argv=None, executable=No...</td>\n",
       "      <td>TypeError</td>\n",
       "      <td>[+] Downloading '/proc/sys/kernel/core_pattern...</td>\n",
       "      <td>def process(self, argv=None, executable=None, ...</td>\n",
       "      <td>def process(self, argv=None, executable=None, ...</td>\n",
       "      <td>cwd = cwd or self.cwd\\n        if isinstance(c...</td>\n",
       "      <td>def process(self, argv=None, executable=None, ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.948990</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.993589</td>\n",
       "      <td>0.997218</td>\n",
       "      <td>0.997338</td>\n",
       "      <td>0.986706</td>\n",
       "      <td>0.990654</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.943865</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.985848</td>\n",
       "      <td>0.987766</td>\n",
       "      <td>0.988095</td>\n",
       "      <td>0.983752</td>\n",
       "      <td>0.983645</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016169</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.032636</td>\n",
       "      <td>3.489469e-36</td>\n",
       "      <td>0.005284</td>\n",
       "      <td>0.258493</td>\n",
       "      <td>0.011682</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.807457</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.691194</td>\n",
       "      <td>0.705416</td>\n",
       "      <td>0.741912</td>\n",
       "      <td>0.818316</td>\n",
       "      <td>0.605140</td>\n",
       "      <td>d1e8f77aa937f586008b06aabb60d1ac</td>\n",
       "      <td>baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532193</th>\n",
       "      <td>def backprojection(calibrated_event_list, pixe...</td>\n",
       "      <td>def backprojection(calibrated_event_list, pixe...</td>\n",
       "      <td>TypeError</td>\n",
       "      <td>import sunpy.data\\n&gt;&gt;&gt; import sunpy.data.sampl...</td>\n",
       "      <td>def backprojection(calibrated_event_list, pixe...</td>\n",
       "      <td>def backprojection(calibrated_event_list, pixe...</td>\n",
       "      <td>def backprojection(calibrated_event_list, pixe...</td>\n",
       "      <td>def backprojection(calibrated_event_list, pixe...</td>\n",
       "      <td>0.835698</td>\n",
       "      <td>0.871159</td>\n",
       "      <td>0.191445</td>\n",
       "      <td>0.681342</td>\n",
       "      <td>0.568953</td>\n",
       "      <td>0.757147</td>\n",
       "      <td>0.847458</td>\n",
       "      <td>0.592105</td>\n",
       "      <td>0.831026</td>\n",
       "      <td>0.862375</td>\n",
       "      <td>0.174448</td>\n",
       "      <td>0.666034</td>\n",
       "      <td>0.549906</td>\n",
       "      <td>0.732113</td>\n",
       "      <td>0.813559</td>\n",
       "      <td>0.592105</td>\n",
       "      <td>0.810626</td>\n",
       "      <td>0.798835</td>\n",
       "      <td>0.172004</td>\n",
       "      <td>0.637508</td>\n",
       "      <td>5.086480e-01</td>\n",
       "      <td>0.696498</td>\n",
       "      <td>0.790960</td>\n",
       "      <td>0.572368</td>\n",
       "      <td>0.714742</td>\n",
       "      <td>0.798102</td>\n",
       "      <td>0.168188</td>\n",
       "      <td>0.652772</td>\n",
       "      <td>0.529190</td>\n",
       "      <td>0.709786</td>\n",
       "      <td>0.790960</td>\n",
       "      <td>0.592105</td>\n",
       "      <td>1ca9ee95a397f49814adbe7531b4e88a</td>\n",
       "      <td>baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357599</th>\n",
       "      <td>def export_annotations(self,export_range,e...</td>\n",
       "      <td>def export_annotations(self,export_range,e...</td>\n",
       "      <td>AttributeError</td>\n",
       "      <td>Traceback (most recent call last):\\nFile \"main...</td>\n",
       "      <td>def export_annotations(self, export_range, exp...</td>\n",
       "      <td>def export_annotations(self, export_range, exp...</td>\n",
       "      <td>def export_annotations(self, export_range, exp...</td>\n",
       "      <td>def export_annotations(self,export_range,expor...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.881880</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.917284</td>\n",
       "      <td>0.729662</td>\n",
       "      <td>0.860795</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.822955</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.702983</td>\n",
       "      <td>0.597002</td>\n",
       "      <td>0.755698</td>\n",
       "      <td>0.883721</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.851922</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.780362</td>\n",
       "      <td>6.339492e-01</td>\n",
       "      <td>0.755698</td>\n",
       "      <td>0.883721</td>\n",
       "      <td>0.815789</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.884472</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.959438</td>\n",
       "      <td>0.914406</td>\n",
       "      <td>0.919994</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2b0af7a3b93947509281e74e469190c6</td>\n",
       "      <td>baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45974</th>\n",
       "      <td>def summarize_corpus(corpus, ratio=0.2):\\n    ...</td>\n",
       "      <td>def summarize_corpus(corpus, ratio=0.2):\\n    ...</td>\n",
       "      <td>TypeError</td>\n",
       "      <td>----------------------------------------------...</td>\n",
       "      <td>def summarize_corpus(corpus, ratio=0.2):\\n    ...</td>\n",
       "      <td>def summarize_corpus(corpus, ratio=0.2):\\n    ...</td>\n",
       "      <td>def summarize_corpus(corpus, ratio=0.2):\\n    ...</td>\n",
       "      <td>def summarize_corpus(corpus, ratio=0.2):\\n    ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.892398</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.733220</td>\n",
       "      <td>0.829038</td>\n",
       "      <td>0.889025</td>\n",
       "      <td>0.847059</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.899234</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.735388</td>\n",
       "      <td>0.850717</td>\n",
       "      <td>0.889025</td>\n",
       "      <td>0.847059</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.906949</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.782450</td>\n",
       "      <td>9.157697e-01</td>\n",
       "      <td>0.966889</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.909631</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.765659</td>\n",
       "      <td>0.897493</td>\n",
       "      <td>0.935363</td>\n",
       "      <td>0.917647</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>9fcbb3b0aa8818b51aba3778799ed601</td>\n",
       "      <td>baseline</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          before_merge_without_docstrings  \\\n",
       "75748       def run(self, cmd, **kwargs):\\n        sel...   \n",
       "583899      def process(self, argv=None, executable=No...   \n",
       "532193  def backprojection(calibrated_event_list, pixe...   \n",
       "357599      def export_annotations(self,export_range,e...   \n",
       "45974   def summarize_corpus(corpus, ratio=0.2):\\n    ...   \n",
       "\n",
       "                           after_merge_without_docstrings  traceback_type  \\\n",
       "75748       def run(self, cmd, **kwargs):\\n        sel...      IndexError   \n",
       "583899      def process(self, argv=None, executable=No...       TypeError   \n",
       "532193  def backprojection(calibrated_event_list, pixe...       TypeError   \n",
       "357599      def export_annotations(self,export_range,e...  AttributeError   \n",
       "45974   def summarize_corpus(corpus, ratio=0.2):\\n    ...       TypeError   \n",
       "\n",
       "                                           full_traceback  \\\n",
       "75748   An unexpected error has occurred: IndexError: ...   \n",
       "583899  [+] Downloading '/proc/sys/kernel/core_pattern...   \n",
       "532193  import sunpy.data\\n>>> import sunpy.data.sampl...   \n",
       "357599  Traceback (most recent call last):\\nFile \"main...   \n",
       "45974   ----------------------------------------------...   \n",
       "\n",
       "                     response_qwen-2.5-coder-32b-instruct  \\\n",
       "75748   def run(self, cmd, **kwargs):\\n    self._creat...   \n",
       "583899  def process(self, argv=None, executable=None, ...   \n",
       "532193  def backprojection(calibrated_event_list, pixe...   \n",
       "357599  def export_annotations(self, export_range, exp...   \n",
       "45974   def summarize_corpus(corpus, ratio=0.2):\\n    ...   \n",
       "\n",
       "                                  response_codestral-2501  \\\n",
       "75748   def run(self, cmd, **kwargs):\\n    self._creat...   \n",
       "583899  def process(self, argv=None, executable=None, ...   \n",
       "532193  def backprojection(calibrated_event_list, pixe...   \n",
       "357599  def export_annotations(self, export_range, exp...   \n",
       "45974   def summarize_corpus(corpus, ratio=0.2):\\n    ...   \n",
       "\n",
       "                                          response_gpt-4o  \\\n",
       "75748   def run(self, cmd, **kwargs):\\n    self._creat...   \n",
       "583899  cwd = cwd or self.cwd\\n        if isinstance(c...   \n",
       "532193  def backprojection(calibrated_event_list, pixe...   \n",
       "357599  def export_annotations(self, export_range, exp...   \n",
       "45974   def summarize_corpus(corpus, ratio=0.2):\\n    ...   \n",
       "\n",
       "                               response_claude-3.5-sonnet  \\\n",
       "75748   def run(self, cmd, **kwargs):\\n    self._creat...   \n",
       "583899  def process(self, argv=None, executable=None, ...   \n",
       "532193  def backprojection(calibrated_event_list, pixe...   \n",
       "357599  def export_annotations(self,export_range,expor...   \n",
       "45974   def summarize_corpus(corpus, ratio=0.2):\\n    ...   \n",
       "\n",
       "        metric_qwen-2.5-coder-32b-instruct_ast_score  \\\n",
       "75748                                       0.000000   \n",
       "583899                                      0.000000   \n",
       "532193                                      0.835698   \n",
       "357599                                      0.000000   \n",
       "45974                                       0.000000   \n",
       "\n",
       "        metric_qwen-2.5-coder-32b-instruct_text_score  \\\n",
       "75748                                        0.688742   \n",
       "583899                                       0.948990   \n",
       "532193                                       0.871159   \n",
       "357599                                       0.881880   \n",
       "45974                                        0.892398   \n",
       "\n",
       "        metric_qwen-2.5-coder-32b-instruct_ast_score_normalized  \\\n",
       "75748                                            0.000000         \n",
       "583899                                           0.000000         \n",
       "532193                                           0.191445         \n",
       "357599                                           0.000000         \n",
       "45974                                            0.000000         \n",
       "\n",
       "        metric_qwen-2.5-coder-32b-instruct_codebleu  \\\n",
       "75748                                      0.533997   \n",
       "583899                                     0.993589   \n",
       "532193                                     0.681342   \n",
       "357599                                     0.917284   \n",
       "45974                                      0.733220   \n",
       "\n",
       "        metric_qwen-2.5-coder-32b-instruct_ngram_match_score  \\\n",
       "75748                                            0.422525      \n",
       "583899                                           0.997218      \n",
       "532193                                           0.568953      \n",
       "357599                                           0.729662      \n",
       "45974                                            0.829038      \n",
       "\n",
       "        metric_qwen-2.5-coder-32b-instruct_weighted_ngram_match_score  \\\n",
       "75748                                            0.432303               \n",
       "583899                                           0.997338               \n",
       "532193                                           0.757147               \n",
       "357599                                           0.860795               \n",
       "45974                                            0.889025               \n",
       "\n",
       "        metric_qwen-2.5-coder-32b-instruct_syntax_match_score  \\\n",
       "75748                                            0.600000       \n",
       "583899                                           0.986706       \n",
       "532193                                           0.847458       \n",
       "357599                                           1.000000       \n",
       "45974                                            0.847059       \n",
       "\n",
       "        metric_qwen-2.5-coder-32b-instruct_dataflow_match_score  \\\n",
       "75748                                            0.647059         \n",
       "583899                                           0.990654         \n",
       "532193                                           0.592105         \n",
       "357599                                           1.000000         \n",
       "45974                                            0.525000         \n",
       "\n",
       "        metric_codestral-2501_ast_score  metric_codestral-2501_text_score  \\\n",
       "75748                          0.000000                          0.826667   \n",
       "583899                         0.000000                          0.943865   \n",
       "532193                         0.831026                          0.862375   \n",
       "357599                         0.000000                          0.822955   \n",
       "45974                          0.000000                          0.899234   \n",
       "\n",
       "        metric_codestral-2501_ast_score_normalized  \\\n",
       "75748                                     0.000000   \n",
       "583899                                    1.000000   \n",
       "532193                                    0.174448   \n",
       "357599                                    0.000000   \n",
       "45974                                     0.000000   \n",
       "\n",
       "        metric_codestral-2501_codebleu  \\\n",
       "75748                         0.533997   \n",
       "583899                        0.985848   \n",
       "532193                        0.666034   \n",
       "357599                        0.702983   \n",
       "45974                         0.735388   \n",
       "\n",
       "        metric_codestral-2501_ngram_match_score  \\\n",
       "75748                                  0.422525   \n",
       "583899                                 0.987766   \n",
       "532193                                 0.549906   \n",
       "357599                                 0.597002   \n",
       "45974                                  0.850717   \n",
       "\n",
       "        metric_codestral-2501_weighted_ngram_match_score  \\\n",
       "75748                                           0.432303   \n",
       "583899                                          0.988095   \n",
       "532193                                          0.732113   \n",
       "357599                                          0.755698   \n",
       "45974                                           0.889025   \n",
       "\n",
       "        metric_codestral-2501_syntax_match_score  \\\n",
       "75748                                   0.600000   \n",
       "583899                                  0.983752   \n",
       "532193                                  0.813559   \n",
       "357599                                  0.883721   \n",
       "45974                                   0.847059   \n",
       "\n",
       "        metric_codestral-2501_dataflow_match_score  metric_gpt-4o_ast_score  \\\n",
       "75748                                     0.647059                 0.000000   \n",
       "583899                                    0.983645                 0.000000   \n",
       "532193                                    0.592105                 0.810626   \n",
       "357599                                    0.631579                 0.000000   \n",
       "45974                                     0.525000                 0.000000   \n",
       "\n",
       "        metric_gpt-4o_text_score  metric_gpt-4o_ast_score_normalized  \\\n",
       "75748                   0.456522                            0.000000   \n",
       "583899                  0.016169                            1.000000   \n",
       "532193                  0.798835                            0.172004   \n",
       "357599                  0.851922                            0.000000   \n",
       "45974                   0.906949                            0.000000   \n",
       "\n",
       "        metric_gpt-4o_codebleu  metric_gpt-4o_ngram_match_score  \\\n",
       "75748                 0.534863                     4.311807e-01   \n",
       "583899                0.032636                     3.489469e-36   \n",
       "532193                0.637508                     5.086480e-01   \n",
       "357599                0.780362                     6.339492e-01   \n",
       "45974                 0.782450                     9.157697e-01   \n",
       "\n",
       "        metric_gpt-4o_weighted_ngram_match_score  \\\n",
       "75748                                   0.432303   \n",
       "583899                                  0.005284   \n",
       "532193                                  0.696498   \n",
       "357599                                  0.755698   \n",
       "45974                                   0.966889   \n",
       "\n",
       "        metric_gpt-4o_syntax_match_score  metric_gpt-4o_dataflow_match_score  \\\n",
       "75748                           0.600000                            0.647059   \n",
       "583899                          0.258493                            0.011682   \n",
       "532193                          0.790960                            0.572368   \n",
       "357599                          0.883721                            0.815789   \n",
       "45974                           0.941176                            0.525000   \n",
       "\n",
       "        metric_claude-3.5-sonnet_ast_score  \\\n",
       "75748                             0.000000   \n",
       "583899                            0.000000   \n",
       "532193                            0.714742   \n",
       "357599                            0.000000   \n",
       "45974                             0.000000   \n",
       "\n",
       "        metric_claude-3.5-sonnet_text_score  \\\n",
       "75748                              0.498246   \n",
       "583899                             0.807457   \n",
       "532193                             0.798102   \n",
       "357599                             0.884472   \n",
       "45974                              0.909631   \n",
       "\n",
       "        metric_claude-3.5-sonnet_ast_score_normalized  \\\n",
       "75748                                        0.000000   \n",
       "583899                                       1.000000   \n",
       "532193                                       0.168188   \n",
       "357599                                       0.000000   \n",
       "45974                                        0.000000   \n",
       "\n",
       "        metric_claude-3.5-sonnet_codebleu  \\\n",
       "75748                            0.484122   \n",
       "583899                           0.691194   \n",
       "532193                           0.652772   \n",
       "357599                           0.959438   \n",
       "45974                            0.765659   \n",
       "\n",
       "        metric_claude-3.5-sonnet_ngram_match_score  \\\n",
       "75748                                     0.294467   \n",
       "583899                                    0.705416   \n",
       "532193                                    0.529190   \n",
       "357599                                    0.914406   \n",
       "45974                                     0.897493   \n",
       "\n",
       "        metric_claude-3.5-sonnet_weighted_ngram_match_score  \\\n",
       "75748                                            0.339630     \n",
       "583899                                           0.741912     \n",
       "532193                                           0.709786     \n",
       "357599                                           0.919994     \n",
       "45974                                            0.935363     \n",
       "\n",
       "        metric_claude-3.5-sonnet_syntax_match_score  \\\n",
       "75748                                      0.600000   \n",
       "583899                                     0.818316   \n",
       "532193                                     0.790960   \n",
       "357599                                     1.000000   \n",
       "45974                                      0.917647   \n",
       "\n",
       "        metric_claude-3.5-sonnet_dataflow_match_score  \\\n",
       "75748                                        0.647059   \n",
       "583899                                       0.605140   \n",
       "532193                                       0.592105   \n",
       "357599                                       1.000000   \n",
       "45974                                        0.525000   \n",
       "\n",
       "                             sample_uuid    prompt  \n",
       "75748   8caf7a732dd1acbd2731a012a8bd45fe  baseline  \n",
       "583899  d1e8f77aa937f586008b06aabb60d1ac  baseline  \n",
       "532193  1ca9ee95a397f49814adbe7531b4e88a  baseline  \n",
       "357599  2b0af7a3b93947509281e74e469190c6  baseline  \n",
       "45974   9fcbb3b0aa8818b51aba3778799ed601  baseline  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "baseline.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "83cd1da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.simple_metrics import wilcoxon_test, has_metrics_columns\n",
    "\n",
    "# Example: Compare two sets of metrics between experiments using Wilcoxon signed-rank test\n",
    "# Let's assume we want to compare 'accuracy' between baseline and system_apr\n",
    "def wilcoxon_test_cross_dataset_simple(\n",
    "    df1: pd.DataFrame,\n",
    "    df2: pd.DataFrame,\n",
    "    model_name: str,\n",
    "    metric_name: str = \"ast_score\",\n",
    "    reference_column: str = \"after_merge_without_docstrings\",\n",
    "    id_column: str = \"bug_id\",\n",
    "    alternative: str = \"two-sided\"\n",
    ") -> Dict[str, float]:\n",
    "    \"\"\"Perform Wilcoxon test for the same model across two datasets using existing function.\n",
    "    \n",
    "    This function reuses the existing wilcoxon_test by merging datasets and creating\n",
    "    separate response columns for each dataset.\n",
    "    \n",
    "    Args:\n",
    "        df1 (pd.DataFrame): First dataset DataFrame\n",
    "        df2 (pd.DataFrame): Second dataset DataFrame  \n",
    "        model_name (str): Name of the model to compare (e.g., \"gpt4\", \"claude\")\n",
    "        metric_name (str): Name of the metric to compare (default: \"ast_score\")\n",
    "        reference_column (str): Reference column used for metric calculation\n",
    "        id_column (str): Column name to match instances across datasets\n",
    "        alternative (str): Alternative hypothesis: \"two-sided\", \"greater\", or \"less\"\n",
    "    \n",
    "    Returns:\n",
    "        Dict[str, float]: Dictionary containing test results from existing wilcoxon_test\n",
    "    \"\"\"\n",
    "    # Find the response column for the specified model in each dataset\n",
    "    response_col1 = None\n",
    "    response_col2 = None\n",
    "    \n",
    "    for col in df1.columns:\n",
    "        if col.startswith(\"response_\") and model_name.lower() in col.lower():\n",
    "            response_col1 = col\n",
    "            break\n",
    "            \n",
    "    for col in df2.columns:\n",
    "        if col.startswith(\"response_\") and model_name.lower() in col.lower():\n",
    "            response_col2 = col\n",
    "            break\n",
    "    \n",
    "    if not response_col1:\n",
    "        raise ValueError(f\"Model '{model_name}' not found in dataset 1\")\n",
    "    if not response_col2:\n",
    "        raise ValueError(f\"Model '{model_name}' not found in dataset 2\")\n",
    "    \n",
    "    # Ensure metrics are computed for both datasets\n",
    "    if not has_metrics_columns(df1, response_col1):\n",
    "        print(f\"Computing metrics for dataset 1...\")\n",
    "        df1 = compute_and_store_metrics(df1, reference_column, [response_col1])\n",
    "    \n",
    "    if not has_metrics_columns(df2, response_col2):\n",
    "        print(f\"Computing metrics for dataset 2...\")\n",
    "        df2 = compute_and_store_metrics(df2, reference_column, [response_col2])\n",
    "    \n",
    "    # Get metric column names\n",
    "    clean_model_name = response_col1.replace(\"response_\", \"\")\n",
    "    metric_col1 = f\"metric_{clean_model_name}_{metric_name}\"\n",
    "    metric_col2 = f\"metric_{clean_model_name}_{metric_name}\"\n",
    "    \n",
    "\n",
    "    merged_df = pd.merge(\n",
    "        df1[[id_column, metric_col1]], \n",
    "        df2[[id_column, metric_col2]], \n",
    "        on=id_column, \n",
    "        how='inner',\n",
    "        suffixes=('_dataset1', '_dataset2')\n",
    "    )\n",
    "    \n",
    "    # Create a unified DataFrame that mimics the structure expected by wilcoxon_test\n",
    "    unified_df = pd.DataFrame({\n",
    "        id_column: merged_df[id_column],\n",
    "        \"response_dataset1\": merged_df[metric_col1 + \"_dataset1\"],\n",
    "        \"response_dataset2\": merged_df[metric_col2 + \"_dataset2\"],\n",
    "        \"dummy_reference\": merged_df[metric_col1 + \"_dataset1\"]  # For compatibility\n",
    "    })\n",
    "    \n",
    "    # Use the existing wilcoxon_test function directly!\n",
    "    return wilcoxon_test(\n",
    "        df=unified_df,\n",
    "        response_column1=\"response_dataset1\",\n",
    "        response_column2=\"response_dataset2\",\n",
    "        metric_name=metric_name,  # This won't be used since we're passing metric values directly\n",
    "        reference_column=\"dummy_reference\",\n",
    "        alternative=alternative\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d28f6b22",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Missing columns: ['metric_dataset1_codebleu', 'metric_dataset2_codebleu']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Compare GPT-4 performance across experiments using existing function\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mwilcoxon_test_cross_dataset_simple\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdf1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbaseline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdf2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msystem_apr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mqwen-2.5-coder-32b-instruct\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcodebleu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mid_column\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msample_uuid\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCross-dataset Wilcoxon test results:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mp-value: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpvalue\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.6f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[29], line 82\u001b[0m, in \u001b[0;36mwilcoxon_test_cross_dataset_simple\u001b[0;34m(df1, df2, model_name, metric_name, reference_column, id_column, alternative)\u001b[0m\n\u001b[1;32m     74\u001b[0m unified_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[1;32m     75\u001b[0m     id_column: merged_df[id_column],\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_dataset1\u001b[39m\u001b[38;5;124m\"\u001b[39m: merged_df[metric_col1 \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_dataset1\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_dataset2\u001b[39m\u001b[38;5;124m\"\u001b[39m: merged_df[metric_col2 \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_dataset2\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdummy_reference\u001b[39m\u001b[38;5;124m\"\u001b[39m: merged_df[metric_col1 \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_dataset1\u001b[39m\u001b[38;5;124m\"\u001b[39m]  \u001b[38;5;66;03m# For compatibility\u001b[39;00m\n\u001b[1;32m     79\u001b[0m })\n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m# Use the existing wilcoxon_test function directly!\u001b[39;00m\n\u001b[0;32m---> 82\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwilcoxon_test\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munified_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_column1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_dataset1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_column2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_dataset2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# This won't be used since we're passing metric values directly\u001b[39;49;00m\n\u001b[1;32m     87\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreference_column\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdummy_reference\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m    \u001b[49m\u001b[43malternative\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malternative\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Developer/BugDetectiveAI/Bugdetectiveai/scr/utils/simple_metrics.py:449\u001b[0m, in \u001b[0;36mwilcoxon_test\u001b[0;34m(df, response_column1, response_column2, metric_name, reference_column, alternative)\u001b[0m\n\u001b[1;32m    446\u001b[0m         missing_columns\u001b[38;5;241m.\u001b[39mappend(col)\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m missing_columns:\n\u001b[0;32m--> 449\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing columns: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmissing_columns\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    451\u001b[0m \u001b[38;5;66;03m# Extract metric values, filtering out NaN values\u001b[39;00m\n\u001b[1;32m    452\u001b[0m values1 \u001b[38;5;241m=\u001b[39m df[metric_col1]\u001b[38;5;241m.\u001b[39mdropna()\n",
      "\u001b[0;31mValueError\u001b[0m: Missing columns: ['metric_dataset1_codebleu', 'metric_dataset2_codebleu']"
     ]
    }
   ],
   "source": [
    "\n",
    "# Compare GPT-4 performance across experiments using existing function\n",
    "results = wilcoxon_test_cross_dataset_simple(\n",
    "    df1=baseline,\n",
    "    df2=system_apr,\n",
    "    model_name=\"qwen-2.5-coder-32b-instruct\",\n",
    "    metric_name=\"codebleu\",\n",
    "    id_column=\"sample_uuid\"\n",
    ")\n",
    "\n",
    "print(f\"Cross-dataset Wilcoxon test results:\")\n",
    "print(f\"p-value: {results['pvalue']:.6f}\")\n",
    "print(f\"Significant difference: {'Yes' if results['significant'] else 'No'}\")\n",
    "print(f\"Effect size: {results['effect_size']:.4f}\")\n",
    "print(f\"Matching instances: {results['matching_instances']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BugDetectiveAI (Poetry)",
   "language": "python",
   "name": "bugdetectiveai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
