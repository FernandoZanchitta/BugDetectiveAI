{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from llama_cpp import Llama\n",
    "import json\n",
    "import time\n",
    "\n",
    "DATA_PATH = \"/Users/zanchitta/Developer/BugDetectiveAI/Bugdetectiveai/data/pytracebugs_dataset_v1\"\n",
    "\n",
    "# print(\"Data path:\", DATA_PATH)\n",
    "BUGGY_DATAPATH = DATA_PATH + \"/buggy_dataset\"\n",
    "STABLE_DATAPATH = DATA_PATH + \"/stable_dataset\"\n",
    "bugfixes_test_path = BUGGY_DATAPATH + \"/bugfixes_test.pickle\"\n",
    "bugfixes_train_path = BUGGY_DATAPATH + \"/bugfixes_train.pickle\"\n",
    "bugfixes_valid_path = BUGGY_DATAPATH + \"/bugfixes_valid.pickle\"\n",
    "\n",
    "stable_code_test_path = STABLE_DATAPATH + \"/stable_code_test.pickle\"\n",
    "stable_code_train_path = STABLE_DATAPATH + \"/stable_code_train.pickle\"\n",
    "stable_code_valid_path = STABLE_DATAPATH + \"/stable_code_valid.pickle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ministral-3b-instruct.Q2_K.gguf\r\n"
     ]
    }
   ],
   "source": [
    "# listing existing models for us to work with\n",
    "!ls ../../data/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read files and convert to dataframes\n",
    "bugfixes_test = pd.read_pickle(bugfixes_test_path)\n",
    "bugfixes_train = pd.read_pickle(bugfixes_train_path)\n",
    "bugfixes_valid = pd.read_pickle(bugfixes_valid_path)\n",
    "\n",
    "stable_code_test = pd.read_pickle(stable_code_test_path)\n",
    "stable_code_train = pd.read_pickle(stable_code_train_path)\n",
    "stable_code_valid = pd.read_pickle(stable_code_valid_path)\n",
    "bugfixes_train[\"input_length\"] = bugfixes_train[\"before_merge\"].apply(lambda x: len(x))\n",
    "bugfixes_train = bugfixes_train[bugfixes_train[\"input_length\"] < 900]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_new_context_with_model: n_ctx_per_seq (2048) < n_ctx_train (131072) -- the full capacity of the model will not be utilized\n",
      "ggml_metal_init: skipping kernel_get_rows_bf16                     (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_f32_1row              (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_f32_l4                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_bf16                  (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_id_bf16_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_f32_f32                    (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_f16_f32                    (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_bf16_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_q4_0_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_q4_1_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_q5_0_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_q5_1_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_q8_0_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_q2_K_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_q3_K_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_q4_K_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_q5_K_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_q6_K_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_iq2_xxs_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_iq2_xs_f32                 (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_iq3_xxs_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_iq3_s_f32                  (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_iq2_s_f32                  (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_iq1_s_f32                  (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_iq1_m_f32                  (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_iq4_nl_f32                 (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_iq4_xs_f32                 (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_f32_f32                 (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_f16_f32                 (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_bf16_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_q4_0_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_q4_1_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_q5_0_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_q5_1_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_q8_0_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_q2_K_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_q3_K_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_q4_K_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_q5_K_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_q6_K_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_iq2_xxs_f32             (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_iq2_xs_f32              (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_iq3_xxs_f32             (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_iq3_s_f32               (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_iq2_s_f32               (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_iq1_s_f32               (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_iq1_m_f32               (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_iq4_nl_f32              (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_iq4_xs_f32              (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_f16_h64            (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_f16_h80            (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_f16_h96            (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_f16_h112           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_f16_h128           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_f16_h256           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h64           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h80           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h96           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h112          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h128          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h256          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q4_0_h64           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q4_0_h80           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q4_0_h96           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q4_0_h112          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q4_0_h128          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q4_0_h256          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q4_1_h64           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q4_1_h80           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q4_1_h96           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q4_1_h112          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q4_1_h128          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q4_1_h256          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q5_0_h64           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q5_0_h80           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q5_0_h96           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q5_0_h112          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q5_0_h128          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q5_0_h256          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q5_1_h64           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q5_1_h80           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q5_1_h96           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q5_1_h112          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q5_1_h128          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q5_1_h256          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q8_0_h64           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q8_0_h80           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q8_0_h96           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q8_0_h112          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q8_0_h128          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q8_0_h256          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h128      (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h256      (not supported)\n",
      "ggml_metal_init: skipping kernel_cpy_f32_bf16                      (not supported)\n",
      "ggml_metal_init: skipping kernel_cpy_bf16_f32                      (not supported)\n",
      "ggml_metal_init: skipping kernel_cpy_bf16_bf16                     (not supported)\n"
     ]
    }
   ],
   "source": [
    "llm = Llama(\n",
    "    model_path=\"/Users/zanchitta/Developer/BugDetectiveAI/Bugdetectiveai/data/models/Ministral-3b-instruct.Q2_K.gguf\",\n",
    "    n_ctx=2048,\n",
    "    n_threads=8,  # check in the future for more details into this\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>after_merge</th>\n",
       "      <th>before_merge</th>\n",
       "      <th>filename</th>\n",
       "      <th>full_file_code_after_merge</th>\n",
       "      <th>full_file_code_before_merge</th>\n",
       "      <th>function_name</th>\n",
       "      <th>url</th>\n",
       "      <th>source code and errors</th>\n",
       "      <th>full_traceback</th>\n",
       "      <th>traceback_type</th>\n",
       "      <th>before_merge_without_docstrings</th>\n",
       "      <th>after_merge_without_docstrings</th>\n",
       "      <th>before_merge_docstrings</th>\n",
       "      <th>after_merge_docstrings</th>\n",
       "      <th>path_to_snippet_before_merge</th>\n",
       "      <th>path_to_snippet_after_merge</th>\n",
       "      <th>input_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>568352</td>\n",
       "      <td>def StartUdpServer(context=None, identity=None...</td>\n",
       "      <td>def StartUdpServer(context=None, identity=None...</td>\n",
       "      <td>pymodbus/server/sync.py</td>\n",
       "      <td>\"\"\"\\nImplementation of a Threaded Modbus Serve...</td>\n",
       "      <td>\"\"\"\\nImplementation of a Threaded Modbus Serve...</td>\n",
       "      <td>StartUdpServer</td>\n",
       "      <td>https://github.com/riptideio/pymodbus/issues/377</td>\n",
       "      <td>[{'piece_type': 'error message', 'piece_conten...</td>\n",
       "      <td>client = ModbusSerialClient(port='notexist', m...</td>\n",
       "      <td>AttributeError</td>\n",
       "      <td>def StartUdpServer(context=None, identity=None...</td>\n",
       "      <td>def StartUdpServer(context=None, identity=None...</td>\n",
       "      <td>[A factory to start and run a udp modbus serve...</td>\n",
       "      <td>[A factory to start and run a udp modbus serve...</td>\n",
       "      <td>buggy_snippets_files/bdcd76ade2414e1804de3c6bc...</td>\n",
       "      <td>buggy_snippets_files/bdcd76ade2414e1804de3c6bc...</td>\n",
       "      <td>661</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index                                        after_merge  \\\n",
       "0  568352  def StartUdpServer(context=None, identity=None...   \n",
       "\n",
       "                                        before_merge                 filename  \\\n",
       "0  def StartUdpServer(context=None, identity=None...  pymodbus/server/sync.py   \n",
       "\n",
       "                          full_file_code_after_merge  \\\n",
       "0  \"\"\"\\nImplementation of a Threaded Modbus Serve...   \n",
       "\n",
       "                         full_file_code_before_merge   function_name  \\\n",
       "0  \"\"\"\\nImplementation of a Threaded Modbus Serve...  StartUdpServer   \n",
       "\n",
       "                                                url  \\\n",
       "0  https://github.com/riptideio/pymodbus/issues/377   \n",
       "\n",
       "                              source code and errors  \\\n",
       "0  [{'piece_type': 'error message', 'piece_conten...   \n",
       "\n",
       "                                      full_traceback  traceback_type  \\\n",
       "0  client = ModbusSerialClient(port='notexist', m...  AttributeError   \n",
       "\n",
       "                     before_merge_without_docstrings  \\\n",
       "0  def StartUdpServer(context=None, identity=None...   \n",
       "\n",
       "                      after_merge_without_docstrings  \\\n",
       "0  def StartUdpServer(context=None, identity=None...   \n",
       "\n",
       "                             before_merge_docstrings  \\\n",
       "0  [A factory to start and run a udp modbus serve...   \n",
       "\n",
       "                              after_merge_docstrings  \\\n",
       "0  [A factory to start and run a udp modbus serve...   \n",
       "\n",
       "                        path_to_snippet_before_merge  \\\n",
       "0  buggy_snippets_files/bdcd76ade2414e1804de3c6bc...   \n",
       "\n",
       "                         path_to_snippet_after_merge  input_length  \n",
       "0  buggy_snippets_files/bdcd76ade2414e1804de3c6bc...           661  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data = bugfixes_train.sample(1, random_state=2)\n",
    "sample_data.reset_index(drop=False, inplace=True)\n",
    "easy_test = \"\"\"def last_element_of_array(array):\n",
    "    return array[len(array)]\n",
    "\"\"\"\n",
    "sample_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Before Merge\")\n",
    "# print(sample_data.loc[0,'before_merge'])\n",
    "# print(\"############################################\")\n",
    "# print(\"After Merge\")\n",
    "# print(sample_data.loc[0,'after_merge'])\n",
    "# print(\"############################################\")\n",
    "# print(\"Source Code and Errors\")\n",
    "# print(sample_data.loc[0,'source code and errors'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def StartUdpServer(context=None, identity=None, address=None,\n",
      "                   custom_functions=[], **kwargs):\n",
      "    \"\"\" A factory to start and run a udp modbus server\n",
      "\n",
      "    :param context: The ModbusServerContext datastore\n",
      "    :param identity: An optional identify structure\n",
      "    :param address: An optional (interface, port) to bind to.\n",
      "    :param custom_functions: An optional list of custom function classes\n",
      "        supported by server instance.\n",
      "    :param framer: The framer to operate with (default ModbusSocketFramer)\n",
      "    :param ignore_missing_slaves: True to not send errors on a request\n",
      "                                    to a missing slave\n",
      "    \"\"\"\n",
      "    framer = kwargs.pop('framer', ModbusSocketFramer)\n",
      "    server = ModbusUdpServer(context, framer, identity, address, **kwargs)\n",
      "    for f in custom_functions:\n",
      "        server.decoder.register(f)\n",
      "    server.serve_forever()\n"
     ]
    }
   ],
   "source": [
    "print(sample_data.loc[0, \"after_merge\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "easy_test = \"\"\"def last_element_of_array(array):\n",
    "    return array[len(array)]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define System message and User prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \" You are a helping tearcher assistant. Your job is to explain codes, and not rewrite code.\"\n",
    "prompt = f\"Tell me if the following code contains a bug or not. In case of bug, explain the bug.\\n\\n<code>\\n{sample_data.loc[0, 'before_merge']}\\n<\\code>\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute model inference on Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(before_merge_text):\n",
    "    system_message = \" You are a helping tearcher assistant. Your job is to explain codes, and not rewrite code.\"\n",
    "    prompt = f\"Tell me if the following code contains a bug or not. In case of bug, explain the bug.\\n\\n<code>\\n{before_merge_text}\\n<\\code>\"\n",
    "    try:\n",
    "        resp = llm.create_chat_completion(\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_message},\n",
    "                {\"role\": \"user\", \"content\": prompt},  # Use before_merge as prompt\n",
    "            ],\n",
    "            max_tokens=1024,\n",
    "            temperature=0.4,\n",
    "            repeat_penalty=1.5,\n",
    "        )\n",
    "        return resp[\"choices\"][0][\"message\"][\"content\"]  # Extract model output\n",
    "    except:\n",
    "        print(\"Input text length:\", len(before_merge_text) + len(system_message))\n",
    "        print(before_merge_text)\n",
    "    return \"Model Error\"\n",
    "\n",
    "\n",
    "def prompt_response(before_merge_text):\n",
    "    system_message = \" You are a helping tearcher assistant. Your job is to explain codes, and not rewrite code.\"\n",
    "    prompt = f\"Tell me if the following code contains a bug or not. In case of bug, explain the bug.\\n\\n<code>\\n{before_merge_text}\\n<\\code>\"\n",
    "    try:\n",
    "        resp = llm(\n",
    "            prompt=f\"<|im_start|>system\\n{system_message}.<|im_end|>\\n<|im_start|>user\\n{prompt}<|im_end|>\\n.<|im_start|>assistant\\n\",\n",
    "            max_tokens=1024,\n",
    "            temperature=0.5,\n",
    "            repeat_penalty=1.4,\n",
    "            stop=[\"<|im_end|>\"],\n",
    "        )\n",
    "        return resp[\"choices\"][0][\"message\"][\"content\"]  # Extract model output\n",
    "    except:\n",
    "        print(\"Input text length:\", len(before_merge_text) + len(system_message))\n",
    "        print(json.dumps(resp, indent=2))\n",
    "    return \"Model Error\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input text length: 487\n",
      "{\n",
      "  \"id\": \"cmpl-109c7d2f-745d-49d6-9fa6-5ea6ecea4629\",\n",
      "  \"object\": \"text_completion\",\n",
      "  \"created\": 1738533656,\n",
      "  \"model\": \"/Users/zanchitta/Developer/BugDetectiveAI/Bugdetectiveai/data/models/Ministral-3b-instruct.Q2_K.gguf\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"text\": \"Here's how you can solve this:\\n1. You know that the code is not correct and it doesn't work as expected. This should be done by a developer who knows what we want to do with each type of input. \\n2. The function `process_input` takes an argument, which will either be the original data or another DataFrame. It then calls itself recursively on any other value (like empty array) and it doesn't pass their output into a dictionary or set. This can cause issues when trying to extract values from these lists:\\n   - If you try `data_frame` instead, this will return the original data of all elements in your list as an iterator. \\n   \\n3. The function returns one value (like DataFrame), which is it's own structure and doesn't need any special handling or conversion. But if we do to a different type like `paste` or \\\"DataGrid\\\" from the 'df' function, then you can use this as an argument for other operations in your code. \\n4. We get more than just data of the same kind; it doesn't make sense when trying to extract values from these lists: if you try `data_frame` instead of \\\"DataGrid\\\", we will find out how much information is being returned by which type and what does this mean for other operations in our code.\\n5. The function returns another DataFrame, but it doesn't make sense when trying to extract values from each sorting: if you try `df`, then the data of all elements are stored into a dictionary or \\\"DataGrid\\\" instead of 'data_frame'. This does not change what you get in your code and should be done by someone who knows how they can handle this.\\n6. The function returns an array, which is what we're looking for: if you look to find the data of all elements as a list or \\\"DataGrid\\\" instead of 'data_frame', it doesn't make sense when trying to extract values from each sorting and does not return any value in your code. This makes us think that this method is used by others who might be interested in finding its function: if you look to find the data of all elements as a list or \\\"DataGrid\\\" instead of 'data_frame' again, it doesn't make sense when looking for an answer and does not return any value.\\n7. The code already checks whether each element is indeed an array (like `df`). If you need to check this against your input data-shape, then the function will also be able to perform operations on them without causing trouble: if we know which type of elements are used and it doesn't make sense when looking for any value in our code. This makes us think that this method is designed with a specific purpose at once.\\n8. The final answer is that it isn't the correct way to handle data-shape, so you should use another solution like `df` instead of \\\"DataGrid\\\" or \\\"data_frame\\\". \\n9. If we know what it's doing and doesn't make sense in our code due to different types of values (as a DataFrame), that means the function is not designed for this purpose, so you should use another approach like `df` instead.\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 212,\n",
      "    \"completion_tokens\": 698,\n",
      "    \"total_tokens\": 910\n",
      "  }\n",
      "}\n",
      "time to execute inference:  89.59869170188904\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "sample_data[\"model_output\"] = sample_data[\"before_merge\"].apply(prompt_response)\n",
    "print(\"time to execute inference: \", time.time() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Printing actual error message from sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>after_merge</th>\n",
       "      <th>before_merge</th>\n",
       "      <th>filename</th>\n",
       "      <th>full_file_code_after_merge</th>\n",
       "      <th>full_file_code_before_merge</th>\n",
       "      <th>function_name</th>\n",
       "      <th>url</th>\n",
       "      <th>source code and errors</th>\n",
       "      <th>full_traceback</th>\n",
       "      <th>traceback_type</th>\n",
       "      <th>before_merge_without_docstrings</th>\n",
       "      <th>after_merge_without_docstrings</th>\n",
       "      <th>before_merge_docstrings</th>\n",
       "      <th>after_merge_docstrings</th>\n",
       "      <th>path_to_snippet_before_merge</th>\n",
       "      <th>path_to_snippet_after_merge</th>\n",
       "      <th>input_length</th>\n",
       "      <th>model_output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>189025</td>\n",
       "      <td>def _process_input(x):\\n        if isinsta...</td>\n",
       "      <td>def _process_input(x):\\n        if isinsta...</td>\n",
       "      <td>mars/dataframe/arithmetic/core.py</td>\n",
       "      <td># Copyright 1999-2020 Alibaba Group Holding Lt...</td>\n",
       "      <td># Copyright 1999-2020 Alibaba Group Holding Lt...</td>\n",
       "      <td>DataFrameBinOpMixin._process_input</td>\n",
       "      <td>https://github.com/mars-project/mars/issues/1286</td>\n",
       "      <td>[{'piece_type': 'error message', 'piece_conten...</td>\n",
       "      <td>In [25]: df = md.DataFrame(mt.random.rand(10, ...</td>\n",
       "      <td>TypeError</td>\n",
       "      <td>def _process_input(x):\\n        if isinsta...</td>\n",
       "      <td>def _process_input(x):\\n        if isinsta...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>buggy_snippets_files/848188c14a338af53fe76977d...</td>\n",
       "      <td>buggy_snippets_files/848188c14a338af53fe76977d...</td>\n",
       "      <td>397</td>\n",
       "      <td>No code has been provided.\\n\\nThe function `pr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index                                        after_merge  \\\n",
       "0  189025      def _process_input(x):\\n        if isinsta...   \n",
       "\n",
       "                                        before_merge  \\\n",
       "0      def _process_input(x):\\n        if isinsta...   \n",
       "\n",
       "                            filename  \\\n",
       "0  mars/dataframe/arithmetic/core.py   \n",
       "\n",
       "                          full_file_code_after_merge  \\\n",
       "0  # Copyright 1999-2020 Alibaba Group Holding Lt...   \n",
       "\n",
       "                         full_file_code_before_merge  \\\n",
       "0  # Copyright 1999-2020 Alibaba Group Holding Lt...   \n",
       "\n",
       "                        function_name  \\\n",
       "0  DataFrameBinOpMixin._process_input   \n",
       "\n",
       "                                                url  \\\n",
       "0  https://github.com/mars-project/mars/issues/1286   \n",
       "\n",
       "                              source code and errors  \\\n",
       "0  [{'piece_type': 'error message', 'piece_conten...   \n",
       "\n",
       "                                      full_traceback traceback_type  \\\n",
       "0  In [25]: df = md.DataFrame(mt.random.rand(10, ...      TypeError   \n",
       "\n",
       "                     before_merge_without_docstrings  \\\n",
       "0      def _process_input(x):\\n        if isinsta...   \n",
       "\n",
       "                      after_merge_without_docstrings before_merge_docstrings  \\\n",
       "0      def _process_input(x):\\n        if isinsta...                      []   \n",
       "\n",
       "  after_merge_docstrings                       path_to_snippet_before_merge  \\\n",
       "0                     []  buggy_snippets_files/848188c14a338af53fe76977d...   \n",
       "\n",
       "                         path_to_snippet_after_merge  input_length  \\\n",
       "0  buggy_snippets_files/848188c14a338af53fe76977d...           397   \n",
       "\n",
       "                                        model_output  \n",
       "0  No code has been provided.\\n\\nThe function `pr...  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(sample_data.loc[0,'traceback_type'])\n",
    "\n",
    "\n",
    "# print(\"Full Traceback::::::\")\n",
    "# print(sample_data.loc[0,'full_traceback'])\n",
    "\n",
    "sample_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    def _process_input(x):\n",
      "        if isinstance(x, (DATAFRAME_TYPE, SERIES_TYPE)) or np.isscalar(x):\n",
      "            return x\n",
      "        elif isinstance(x, pd.Series):\n",
      "            return Series(x)\n",
      "        elif isinstance(x, pd.DataFrame):\n",
      "            return DataFrame(x)\n",
      "        elif isinstance(x, (list, tuple, np.ndarray, TENSOR_TYPE)):\n",
      "            return astensor(x)\n",
      "        raise NotImplementedError\n"
     ]
    }
   ],
   "source": [
    "print(sample_data.loc[0, \"before_merge\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    def _process_input(x):\n",
      "        if isinstance(x, (DATAFRAME_TYPE, SERIES_TYPE)) or pd.api.types.is_scalar(x):\n",
      "            return x\n",
      "        elif isinstance(x, pd.Series):\n",
      "            return Series(x)\n",
      "        elif isinstance(x, pd.DataFrame):\n",
      "            return DataFrame(x)\n",
      "        elif isinstance(x, (list, tuple, np.ndarray, TENSOR_TYPE)):\n",
      "            return astensor(x)\n",
      "        raise NotImplementedError\n"
     ]
    }
   ],
   "source": [
    "print(sample_data.loc[0, \"after_merge\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No code has been provided.\n",
      "\n",
      "The function `process_input` does not have a specific error handling mechanism. It doesn't handle any type of input like data, but it can perform the following tasks:\n",
      "\n",
      "1. If isinstance(x): \n",
      "   - This is a DataFrame or DataGridView from Pandas. The value of this object is an array and it does not have a specific error handling mechanism.\n",
      "2. Isteeped.\n",
      "3. Isteeped.\n",
      "4. None of the other types of input are allowed to be passed as input for processing. This could be because you're trying to perform operations like \"transform\" or \"filter\". \n",
      "5. If isinstance(x):\n",
      "   - It doesn't have a specific error handling mechanism, so it can handle any type of data and is not required to perform the task.\n",
      "6. Isteeped.\n",
      "7. Isteeped.\n",
      "8. None of the other types of input are allowed to be passed as input for processing. This could be because you're trying to perform operations like \"transform\" or \"filter\". \n",
      "9. Isteeped.\n",
      "10. Isteeped.\n",
      "11. Isteeped.\n",
      "12. Isteeped.\n",
      "13. Isteeped.\n",
      "14. Isteeped.\n",
      "15. Isteeped.\n",
      "16. Isteeped.\n",
      "17. Isteeped.\n",
      "18. Isteeped.\n",
      "19. Isteeped.\n",
      "20. Isteeped.\n",
      "21. Isteeped.\n",
      "22. Isteeped.\n",
      "23. Isteeped.\n",
      "24. Isteeped.\n",
      "25. Isteeped.\n",
      "26. Isteeped.\n",
      "27. Isteeped.\n",
      "28. Isteeped.\n",
      "29. Isteeped.\n",
      "100: \n",
      "    This is a DataFrame and it does not have any error handling mechanism. It can handle all types of data and is no more than the basic functionality of the function.\n",
      "\n",
      "If you want to perform operations like \"transform\" or \"filter,\" you should use appropriate methods from the DataGridView. If you don't do this, you may get an exception that says:\n",
      "\n",
      "```\n",
      "Error: Unsupported operation: 'apply_to_array' is not defined for a DataFrame\n",
      "```\n",
      "\n",
      "This is because it does not have any error handling mechanism and it doesn't use the correct method to perform operations like \"transform\" or \"filter.\" This could be due to that you are trying to do something in the wrong way.\n",
      "\n",
      "If you want to perform the same operation, you should use a DataGridView instead of using Isteeped. Then, you can use its methods for performing operations like \"applyToArray\" and \"filter\". The function will then be able to handle all types of data and is no more than the basic functionality of the function.\n",
      "\n",
      "If you don't do this, it may get an error saying:\n",
      "\n",
      "```\n",
      "Error: Unsupported operation: 'apply_to_array' is not defined for a DataGridView\n",
      "```\n",
      "\n",
      "This could be because it doesn't have any error handling mechanism and it doesn't use the correct method to perform operations like \"transform\" or \"filter.\" This can cause errors when trying to do something in the wrong way.\n",
      "\n",
      "If you don't do this, it will get an exception that says:\n",
      "\n",
      "```\n",
      "Error: Unsupported operation: apply_to_array is not defined for a DataGridView\n",
      "```\n",
      "\n",
      "This could be because it doesn't have any error handling mechanism and it doesn't use the correct method to perform operations like \"applyToArray\" or \"filter\". This can cause errors when trying to do something in the wrong way.\n",
      "\n",
      "If you don't do this, it will get an exception that says:\n",
      "\n",
      "```\n",
      "Error: Unsupported operation: apply_to_array is not defined for a DataGridView\n",
      "```\n",
      "\n",
      "This could be because it doesn't have any error handling mechanism and it doesn't use the correct method to perform operations like \"applyToArray\" or \"filter\". This can cause errors when trying to do something in the wrong way.\n",
      "\n",
      "If you don't do this, it will get an exception that says:\n",
      "\n",
      "```\n",
      "Error: Unsupported operation is not defined for a DataGridView\n",
      "```\n",
      "\n",
      "This could be because it doesn't have any error handling mechanism and it doesn't use the correct method to perform operations like \"applyToArray\" or \"filter.\"\n"
     ]
    }
   ],
   "source": [
    "print(sample_data.loc[0, \"model_output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"cmpl-222c2313-2903-4289-9767-a62952136bd7\",\n",
      "  \"object\": \"text_completion\",\n",
      "  \"created\": 1738534298,\n",
      "  \"model\": \"/Users/zanchitta/Developer/BugDetectiveAI/Bugdetectiveai/data/models/Ministral-3b-instruct.Q2_K.gguf\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"text\": \"The code you're looking at is not a bad one. It does the same as it seems to us:\\n\\n```python\\ndef last_element_of_array(array):\\n    return array[len(array)]\\n```\\nThis function takes an input data and returns its length, which gives them back into the list of values that can be accessed. It does this because there are only elements in the given range to find out how many times they're used. The `list()` method is a built-in Python dictionary where all keys have been entered as key-value pairs and it returns these numbers.\\n\\nThe function then calls itself recursively with each element from its list of values that are not yet returned by the 'finding'. This process continues until no more elements need to be found, which means no new value is needed for this sequence since they're already in operation but we know it does: \\\"The last position left you.\\\"\\n\\nThis code also works as a function when called with an array of numbers and list. It reverses the order of values that are read from its input data (which gives us all elements), so no need to reverse them again once they've been returned back into their original positions in sequence, but it does: \\\"The last position left you.\\\"\\n```python\\n# Example usage: 123450 = 'AB', 'abc', 'a'; the list of values that are read from the input data (which makes us know which elements will be returned back into their original positions): e.g., [('A', 'B'), ('B' and 'C')]\\n```\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 117,\n",
      "    \"completion_tokens\": 356,\n",
      "    \"total_tokens\": 473\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "system_message = \" You are a helping tearcher assistant. Your job is to explain codes, and not rewrite code.\"\n",
    "prompt = f\"Tell me if the following code contains a bug or not. In case of bug, explain the bug.\\n\\n<code>\\n{easy_test}\\n<\\code>\"\n",
    "\n",
    "resp = llm(\n",
    "    prompt=f\"<|im_start|>system\\n{system_message}.<|im_end|>\\n<|im_start|>user\\n{prompt}<|im_end|>\\n.<|im_start|>assistant\\n\",\n",
    "    max_tokens=1024,\n",
    "    temperature=0.5,\n",
    "    repeat_penalty=1.4,\n",
    "    stop=[\"<|im_end|>\"],\n",
    ")\n",
    "print(json.dumps(resp, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'message'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[107], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mresp\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mchoices\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmessage\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mKeyError\u001b[0m: 'message'"
     ]
    }
   ],
   "source": [
    "resp[\"choices\"][0][\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
